{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Written using Python 3.9.7\n",
    "#Author: icebreaker, May 2022\n",
    "\n",
    "from time import sleep, time\n",
    "from web3 import Web3\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "from os.path import exists\n",
    "from hexbytes import HexBytes\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "cg = CoinGeckoAPI()\n",
    "from textwrap import wrap\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ETHERSCAN_API_KEY = os.getenv(\"ETHERSCAN_API_KEY\")\n",
    "INFURA_KEY = ps.getenv(\"INFURA_API_KEY\")\n",
    "\n",
    "ETHERSCAN_API_BASE_URL = \"https://api.etherscan.io/api\"\n",
    "\n",
    "w3 = Web3(Web3.HTTPProvider(\"https://mainnet.infura.io/v3/{}\".format(INFURA_KEY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTargetTX(startBlock, blockStep, _targetEventTopicSignature, _fileNamePreFix):\n",
    "    targetEventTopicSignature = _targetEventTopicSignature\n",
    "    fileNamePreFix = _fileNamePreFix\n",
    "    latestBlockNumber = startBlock\n",
    "    currentBlockNumber = w3.eth.get_block_number()\n",
    "    filteredTXs = []\n",
    "\n",
    "    while latestBlockNumber < currentBlockNumber:\n",
    "        eventFilter = w3.eth.filter(\n",
    "            {\n",
    "                \"fromBlock\": latestBlockNumber,\n",
    "                \"toBlock\": latestBlockNumber + blockStep,\n",
    "                #\"address\": targetContract,\n",
    "                \"topics\": [targetEventTopicSignature],\n",
    "            }\n",
    "        )\n",
    "        txLogs = w3.eth.get_filter_logs(eventFilter.filter_id)\n",
    "\n",
    "        if len(txLogs):\n",
    "            ts = pd.to_datetime((w3.eth.get_block(latestBlockNumber)[\"timestamp\"]), unit='s').to_datetime64()\n",
    "            print(\n",
    "                datetime.now().strftime(\"%H:%M:%S\"), \n",
    "                \"Time: {} Covering Block {}-{}: Found {} {} Transfer events\".format(\n",
    "                    ts,\n",
    "                    latestBlockNumber,\n",
    "                    latestBlockNumber + blockStep,\n",
    "                    len(txLogs),\n",
    "                    fileNamePreFix\n",
    "                )\n",
    "            )\n",
    "            idx = 0\n",
    "            for log in txLogs:\n",
    "                txnHash = log[\"transactionHash\"]\n",
    "                print(\"Getting TX: \",txnHash.hex(), \" \", idx, \" of\", len(txLogs))\n",
    "\n",
    "                txn = w3.eth.get_transaction(txnHash)\n",
    "                gasLimit = txn[\"gas\"]\n",
    "                gasPrice = txn[\"gasPrice\"]\n",
    "                blockNumber = txn[\"blockNumber\"]\n",
    "\n",
    "                txnReceipt = w3.eth.get_transaction_receipt(txnHash)\n",
    "                gasUsed = txnReceipt[\"gasUsed\"]\n",
    "\n",
    "                block = w3.eth.get_block(blockNumber)\n",
    "                timestamp = block[\"timestamp\"]\n",
    "\n",
    "\n",
    "                try:\n",
    "                    mainMethodID = txn.input[:10]\n",
    "                    mainPayload = txn.input[10:]\n",
    "                    mainPayloadTokenized = wrap(mainPayload,64)\n",
    "                    mainOffset = int((int(mainPayloadTokenized[2],16) * 2) / 64)\n",
    "                    mainLength = int(mainPayloadTokenized[mainOffset],16) * 2\n",
    "                    gnosisDataInput = txn.input[((mainOffset + 1) * 64 ) + 10: ((mainOffset + 1) * 64) + mainLength + 10]\n",
    "                    nestedMethodID = \"0x\" + gnosisDataInput[:8]\n",
    "                    nestedPayload = gnosisDataInput[8:]\n",
    "\n",
    "                    filteredTXs.append(\n",
    "                    {\n",
    "                            \"txHash\": txnHash.hex(),\n",
    "                            \"gasLimit\": int(gasLimit),\n",
    "                            \"gasUsed\": int(gasUsed),\n",
    "                            \"gasPrice\": int(gasPrice),\n",
    "                            \"timestamp\": timestamp,\n",
    "                            \"blockNumber\": blockNumber,\n",
    "                            \"from\": txn[\"from\"],\n",
    "                            \"to\": txn[\"to\"],\n",
    "                            'payloadTO' : '0x' + mainPayloadTokenized[0][24:],\n",
    "                            'payloadValue' : '0x' + mainPayloadTokenized[1],\n",
    "                            'payloadMethodID' : mainMethodID,\n",
    "                            'payLoadOffset': mainOffset,\n",
    "                            'payLoadLength': mainLength,\n",
    "                            'nestedMethodID' : nestedMethodID,\n",
    "                            'nestedPayload' : nestedPayload\n",
    "                        }\n",
    "                    )\n",
    "                except:\n",
    "                    print(\"error\")\n",
    "                idx += 1\n",
    "            latestBlockNumber += blockStep\n",
    "\n",
    "        # sleep to avoid getting rate limited\n",
    "        sleep(0.001)\n",
    "    # Save all the order fill data in a pickle file\n",
    "    print(\"Found {} total tradExecs \", fileNamePreFix ,\" fills\".format(len(filteredTXs)))\n",
    "    return filteredTXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicSig = '0x442e715f626346e8c54381002da614f62bee8d27386535b2521ec8540898556e' #transferExec\n",
    "\n",
    "currentBlockNumber = w3.eth.get_block_number()\n",
    "#Finding and scraping onchain tx's of interest takes approximately ~2 hours via infura\n",
    "v2Events = findTargetTX(14710000, 10000, topicSig, 'tradeRebalExecs')\n",
    "\n",
    "columnsFromScrape = [\"txHash\",\"gasLimit\",\"gasUsed\",\"gasPrice\", \"timestamp\",\"blockNumber\",\"from\",\"to\",'payloadTO','payloadValue','payloadMethodID', 'payLoadOffset', 'payLoadLength', 'nestedMethodID', 'nestedPayload']\n",
    "finals = pd.DataFrame(v2Events, columns = columnsFromScrape)\n",
    "finals['datetime'] = list(map(lambda x: datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3], finals[\"timestamp\"]))\n",
    "\n",
    "combinedFills = pd.concat([finals])\n",
    "np.save(\"gnosisExecTXs\", np.array(combinedFills), allow_pickle=True)\n",
    "combinedFills.to_csv(\"combinedFills.to_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedFills = pd.read_csv(\"combinedFills.to_csv\")\n",
    "cols = combinedFills.columns\n",
    "\n",
    "combinedFills = np.load(\"gnosisExecTXs.npy\", allow_pickle=True)\n",
    "combinedFills = pd.DataFrame(combinedFills)\n",
    "combinedFills.columns = cols[1:]\n",
    "combinedFills.reset_index()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#Counter(combinedFills['nestedMethodID'])\n",
    "Counter(combinedFills['payloadTO'])\n",
    "\n",
    "df1 = combinedFills.groupby('payloadTO').size().sort_values().reset_index(name='count')\n",
    "df1.to_csv(\"topTo.csv\")\n",
    "\n",
    "#UNIWAPV2 Message Parser from Gnosis execTransfer Payload <- Used to debug, generalised transfer solution\n",
    "def decodUniV2TXSentToken(pl):\n",
    "    _pl =pl[32:]\n",
    "    plw = wrap(_pl,64)\n",
    "    sendToken = '0x' + plw[5][:40]\n",
    "    return sendToken\n",
    "\n",
    "def decodUniV2TXRecToken(pl):\n",
    "    _pl =pl[32:]\n",
    "    plw = wrap(_pl,64)\n",
    "    receiveToken = '0x' + plw[6][:40]\n",
    "    return [receiveToken]\n",
    "\n",
    "def decodUniV2TXSentTokenAmount(pl):\n",
    "    _pl =pl[32:]\n",
    "    plw = wrap(_pl,64)\n",
    "    amountSent = int((plw[9][:40]),16)  \n",
    "    return [amountSent]\n",
    "\n",
    "listOfProtocols = ['0x68b3465833fb72a70ecdf485e0e4c7bd8665fc45' , '0x7d2768de32b0b80b7a3454c06bdac94a69ddc7a9', '0xc36442b4a4522e871399cd717abdd847ab11fe88', '0x1111111254fb6c44bac0bed2854e76f90643097d', '0x9008d19f58aabd9ed0d60971565aa8510560ab41']\n",
    "uniswapTxDF = combinedFills[combinedFills['payloadTO'].isin(listOfProtocols)]\n",
    "uniswapTxDF['sendToken'] = uniswapTxDF['nestedPayload'].apply(decodUniV2TXSentToken)\n",
    "uniswapTxDF['receiveToken'] = uniswapTxDF['nestedPayload'].apply(decodUniV2TXRecToken)\n",
    "uniswapTxDF['amountSent'] = uniswapTxDF['nestedPayload'].apply(decodUniV2TXSentTokenAmount)\n",
    "\n",
    "uniswapTxDF[['amountSent'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download transfer data\n",
    "\n",
    "transferTopicSignature = \"0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef\"\n",
    "wethAdd = '0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2'\n",
    "\n",
    "sellTransactions = []\n",
    "transferEvents = []\n",
    "idx = 0\n",
    "\n",
    "for log in uniswapTxDF['txHash']:\n",
    "    idx = idx + 1\n",
    "\n",
    "    txnHash = log\n",
    "    #txnHash = '0xb247c4d01e521fa4e5db280ef907b43aa5639e427d5183940a745adc168cd2e8'\n",
    "    txDetails = w3.eth.get_transaction(txnHash)\n",
    "    txReceipt = w3.eth.get_transaction_receipt(txnHash)\n",
    "    txLogLen = len(txReceipt.logs)\n",
    "\n",
    "    transferFound = False\n",
    "    \n",
    "    for logNested in range(0,txLogLen):\n",
    "            #print(\"Working: \" , log/txLogLen, \"%\")\n",
    "        try:\n",
    "            if txReceipt.logs[logNested].topics[0].hex() == transferTopicSignature:\n",
    "                print(\"transferFound\")\n",
    "                tokenAddress = txReceipt.logs[logNested].address\n",
    "                amount = int(txReceipt.logs[logNested].data,16)\n",
    "                transferEvents.append([txnHash, txDetails.value, tokenAddress, amount])    \n",
    "                print(idx, len(uniswapTxDF), txnHash, tokenAddress, amount)\n",
    "                break \n",
    "        except:\n",
    "            tokenAddress = txReceipt.logs[logNested].address\n",
    "            amount = 0\n",
    "            transferEvents.append([txnHash, txDetails.value, tokenAddress, amount])    \n",
    "            print(\"ERROR\", idx, len(uniswapTxDF), txnHash, tokenAddress, amount)\n",
    "\n",
    "            break\n",
    "\n",
    "    sleep(0.01)\n",
    "    \n",
    "transferUniV2Events = pd.DataFrame (transferEvents, columns = ['txnHash', 'value', 'tokenAddress', 'amount'])\n",
    "transferUniV2Events.to_csv(\"transferEvents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transferUniV2Events = pd.read_csv(\"transferEvents.csv\")\n",
    "\n",
    "#ADD IN Symbols and Decimals\n",
    "uniqueTokens = transferUniV2Events['tokenAddress']\n",
    "uniqueTokens = uniqueTokens.unique()\n",
    "\n",
    "with open('./abi/erc20.abi') as json_file:\n",
    "    erc20ABI = json.load(json_file)\n",
    "\n",
    "metaData=[]\n",
    "idx = 0 \n",
    "lent = len(uniqueTokens)\n",
    "for token in uniqueTokens:\n",
    "    idx = 1 + idx\n",
    "    print(idx, lent, token)\n",
    "    try:\n",
    "\n",
    "        contract = w3.eth.contract(w3.toChecksumAddress(token), abi=erc20ABI)\n",
    "        symbol = contract.functions.symbol().call()\n",
    "\n",
    "        metaData.append(\n",
    "        {\n",
    "            \"tokenAddress\": token,\n",
    "            \"decimals\": contract.functions.decimals().call(),\n",
    "            \"symbol\" : symbol\n",
    "        })\n",
    "\n",
    "    except:\n",
    "        print(\"ERROR\", idx, lent, token, )\n",
    "        symbol = \"MKR\" #catch MKR's bytes32 symbol encoding\n",
    "\n",
    "    sleep(0.1)\n",
    "\n",
    "\n",
    "sellMetaDataDF = pd.DataFrame(data=metaData)\n",
    "sellMetaDataDF.columns =['tokenAddress','sellDecimals','sellSymbol']\n",
    "\n",
    "tradeExecs = pd.merge(transferUniV2Events, \n",
    "                     sellMetaDataDF, \n",
    "                     left_on ='tokenAddress',\n",
    "                     right_on ='tokenAddress',\n",
    "                     how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniswapTxDF = pd.merge(tradeExecs, \n",
    "                     uniswapTxDF, \n",
    "                     left_on ='txnHash',\n",
    "                     right_on ='txHash',\n",
    "                     how ='left')\n",
    "\n",
    "tradeExecs = uniswapTxDF\n",
    "\n",
    "#Get approx USD amount, do this by creating a primary key of sold token + date and then making it unique, \n",
    "# run the query (contract address + date) vs coingeckos API to get USD mark then join back to main DF\n",
    "uniquePriceQueries = []\n",
    "tradeExecs['datetime'] = list(map(lambda x: datetime.fromtimestamp(x).strftime('%d-%m-%Y'), tradeExecs[\"timestamp\"]))\n",
    "cols = ['tokenAddress', 'datetime']\n",
    "tradeExecs['uniquePriceQueriesPK'] = tradeExecs[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPriceUSD(contractAdd, date):\n",
    "    id = cg.get_coin_info_from_contract_address_by_id('ethereum',contractAdd).get('id')\n",
    "    price = cg.get_coin_history_by_id(id, date).get('market_data').get('current_price').get('usd')\n",
    "    return price\n",
    "i = 0 \n",
    "\n",
    "for priceQuery in (tradeExecs['uniquePriceQueriesPK'].unique()):\n",
    "    contract = (priceQuery[:42])\n",
    "    date = (priceQuery[-10:])\n",
    "\n",
    "    try: \n",
    "        uniquePriceQueries.append({\n",
    "        'uniquePriceQueriesPK' : priceQuery,\n",
    "        'approxUSDMarkSell' : getPriceUSD(contract, date)\n",
    "        })\n",
    "    except:\n",
    "        uniquePriceQueries.append({\n",
    "        'uniquePriceQueriesPK' : priceQuery,\n",
    "        'approxUSDMarkSell' : 0\n",
    "        })\n",
    "    print(i, \"/\", len(tradeExecs['uniquePriceQueriesPK'].unique()))\n",
    "    i += 1\n",
    "    sleep(.5) #run the query slow, because CG is not l33t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prices to trades\n",
    "tradeExecs['amount'] = tradeExecs['amount'].astype(float) / ( 10 ** tradeExecs['sellDecimals'])\n",
    "\n",
    "priceQueryDF = pd.DataFrame(data=uniquePriceQueries)\n",
    "priceQueryDF.columns =['uniquePriceQueriesPK', 'approxUSDMarkSell']\n",
    "tradeExecs = pd.merge(tradeExecs, \n",
    "                     priceQueryDF, \n",
    "                     left_on ='uniquePriceQueriesPK',\n",
    "                     right_on ='uniquePriceQueriesPK',\n",
    "                     how ='left')\n",
    "                \n",
    "tradeExecs['totalTradeValue'] = tradeExecs['amount'] * tradeExecs['approxUSDMarkSell'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeExecs['totalTradeValue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dump Numpy and CSV of tradeExec DF to disk\n",
    "np.save(\"protocolActivityFinal\" , np.array(tradeExecs), allow_pickle=True)\n",
    "tradeExecs.to_csv(\"protocolActivityFinal.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a9575c58420cef24ec28954c6d8135f52e19e99e6a7cc26bd5467d79abb31f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('keeperDAO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
